model=Sequential()

model.add(Conv2D(16,(3,3), 1, activation='relu', input_shape=(256,256,3))) #Input layer: Filters=16, Filter Size=(3,3), Stride= 1
model.add(MaxPooling2D()) #First maxpooling layer. Reduces size of feature maps by taking max value in a pool size (default pool size= 2x2)

model.add(Conv2D(32,(3,3),1, activation='relu')) #2nd convolutional layer 
model.add(MaxPooling2D())

model.add(Conv2D(16,(3,3),1, activation='relu')) #3rd convolutional layer
model.add(MaxPooling2D())

model.add(Flatten()) #flattened out matrices to align the values in a single dimension (1D)

model.add(Dense(256,activation='relu', kernel_regularizer=l2(0.007))) #fully connected dense layer with 256 nodes
model.add(Dense(1,activation='sigmoid')) #output layer
#model.add(Dense(1,activation='sigmoid',kernel_regularizer=l2(0.01))) #output layer

model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics= ['accuracy'])

model.summary()

hist=model.fit(train,epochs=10, validation_data=val)

fig=plt.figure()
plt.plot(hist.history['loss'], color='teal', label='loss')
plt.plot(hist.history['val_loss'], color='orange', label='val_loss')
fig.suptitle('Loss', fontsize=20)
plt.legend(loc="upper left")
plt.show()


fig=plt.figure()
plt.plot(hist.history['accuracy'], color='teal', label='accuracy')
plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')
fig.suptitle('Accuracy', fontsize=20)
plt.legend(loc="upper left")
plt.show()

precision = Precision()
recall = Recall()
accuracy = BinaryAccuracy()

# Initialize lists to hold true and predicted labels
y_true = []
y_pred = []

# Iterate through the test data
for batch in test.as_numpy_iterator():
    X, y = batch
    y_true.extend(y)  # No need to call y.numpy()
    yhat = model.predict(X)
    y_pred.extend(np.round(yhat).flatten())  # Convert probabilities to class labels
    precision.update_state(y, yhat)
    recall.update_state(y, yhat)
    accuracy.update_state(y, yhat)

# Compute final metric values
precision_value = precision.result().numpy()
recall_value = recall.result().numpy()
accuracy_value = accuracy.result().numpy()

# Print final metric values
print(f"Precision: {precision_value:.4f}")
print(f"Recall: {recall_value:.4f}")
print(f"Accuracy: {accuracy_value:.4f}")

# Convert lists to numpy arrays for confusion matrix calculation
y_true = np.array(y_true)
y_pred = np.array(y_pred)

# Generate confusion matrix
cm = confusion_matrix(y_true, y_pred)

# Plot confusion matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['Bike', 'Car'], yticklabels=['Bike', 'Car'])
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()


